{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0eNlz/W2PIrYiUjvilTQM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdSyfulIslam/CSE-412-Machine-Learning-Lab/blob/main/Lab_Report_2_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "tDv3txHmRYsD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2)**2))\n",
        "\n",
        "class CustomKNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        return np.array([self._predict(x) for x in X_test])\n",
        "\n",
        "    def _predict(self, x):\n",
        "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_labels = [self.y_train[i] for i in k_indices]\n",
        "        return Counter(k_labels).most_common(1)[0][0]\n"
      ],
      "metadata": {
        "id": "G5WeR4gJUTqd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "def custom_confusion_matrix(y_true, y_pred):\n",
        "    labels = np.unique(np.concatenate((y_true, y_pred)))\n",
        "    matrix = np.zeros((len(labels), len(labels)), dtype=int)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        matrix[t][p] += 1\n",
        "    return matrix\n",
        "\n",
        "def custom_precision(y_true, y_pred, label):\n",
        "    tp = np.sum((y_pred == label) & (y_true == label))\n",
        "    fp = np.sum((y_pred == label) & (y_true != label))\n",
        "    return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "def custom_recall(y_true, y_pred, label):\n",
        "    tp = np.sum((y_pred == label) & (y_true == label))\n",
        "    fn = np.sum((y_pred != label) & (y_true == label))\n",
        "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "def custom_f1(y_true, y_pred, label):\n",
        "    p = custom_precision(y_true, y_pred, label)\n",
        "    r = custom_recall(y_true, y_pred, label)\n",
        "    return 2 * p * r / (p + r) if (p + r) > 0 else 0\n"
      ],
      "metadata": {
        "id": "d3wLOhCkUd_1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X_iris, y_iris = iris.data, iris.target\n",
        "\n",
        "best_k_iris = None\n",
        "best_acc_iris = 0\n",
        "best_ratio_iris = 0\n",
        "best_y_iris = {}\n",
        "\n",
        "for k in range(1, 11):\n",
        "    for ratio in [0.2, 0.3, 0.4]:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=ratio, random_state=42)\n",
        "        model = CustomKNN(k)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = custom_accuracy(y_test, y_pred)\n",
        "\n",
        "        if acc > best_acc_iris:\n",
        "            best_acc_iris = acc\n",
        "            best_k_iris = k\n",
        "            best_ratio_iris = ratio\n",
        "            best_y_iris = {'y_test': y_test, 'y_pred': y_pred}\n",
        "\n",
        "print(f\"Iris Dataset: Best Accuracy = {best_acc_iris:.2f}, Best k = {best_k_iris}, Split = {int((1-best_ratio_iris)*100)}:{int(best_ratio_iris*100)}\")\n",
        "print(\"Confusion Matrix:\\n\", custom_confusion_matrix(best_y_iris['y_test'], best_y_iris['y_pred']))\n",
        "for lbl in np.unique(best_y_iris['y_test']):\n",
        "    print(f\"Class {lbl}: Precision = {custom_precision(best_y_iris['y_test'], best_y_iris['y_pred'], lbl):.2f}, \"\n",
        "          f\"Recall = {custom_recall(best_y_iris['y_test'], best_y_iris['y_pred'], lbl):.2f}, \"\n",
        "          f\"F1 = {custom_f1(best_y_iris['y_test'], best_y_iris['y_pred'], lbl):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7ywaaGhUpAy",
        "outputId": "74febe27-7222-4b9f-92d6-2e3b398694dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iris Dataset: Best Accuracy = 1.00, Best k = 1, Split = 80:20\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "Class 0: Precision = 1.00, Recall = 1.00, F1 = 1.00\n",
            "Class 1: Precision = 1.00, Recall = 1.00, F1 = 1.00\n",
            "Class 2: Precision = 1.00, Recall = 1.00, F1 = 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.read_csv(\"news_data.csv\").dropna()\n",
        "texts = news_df['message'].astype(str).tolist()\n",
        "labels = news_df['label'].tolist()\n",
        "\n",
        "vocab = sorted(set(word.lower() for text in texts for word in text.split()))\n",
        "def text_to_vector(text):\n",
        "    words = text.lower().split()\n",
        "    return np.array([words.count(word) for word in vocab])\n",
        "\n",
        "X_news = np.array([text_to_vector(text) for text in texts])\n",
        "le = LabelEncoder()\n",
        "y_news = le.fit_transform(labels)\n",
        "\n",
        "best_k_news = None\n",
        "best_acc_news = 0\n",
        "best_ratio_news = 0\n",
        "best_y_news = {}\n",
        "\n",
        "for k in range(1, 11):\n",
        "    for ratio in [0.2, 0.3, 0.4]:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_news, y_news, test_size=ratio, random_state=42)\n",
        "        model = CustomKNN(k)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = custom_accuracy(y_test, y_pred)\n",
        "\n",
        "        if acc > best_acc_news:\n",
        "            best_acc_news = acc\n",
        "            best_k_news = k\n",
        "            best_ratio_news = ratio\n",
        "            best_y_news = {'y_test': y_test, 'y_pred': y_pred}\n",
        "\n",
        "\n",
        "print(f\" News Dataset: Best Accuracy = {best_acc_news:.2f}, Best k = {best_k_news}, Split = {int((1-best_ratio_news)*100)}:{int(best_ratio_news*100)}\")\n",
        "print(\"Confusion Matrix:\\n\", custom_confusion_matrix(best_y_news['y_test'], best_y_news['y_pred']))\n",
        "for lbl in np.unique(best_y_news['y_test']):\n",
        "    print(f\"Class {lbl} ({le.classes_[lbl]}): Precision = {custom_precision(best_y_news['y_test'], best_y_news['y_pred'], lbl):.2f}, \"\n",
        "          f\"Recall = {custom_recall(best_y_news['y_test'], best_y_news['y_pred'], lbl):.2f}, \"\n",
        "          f\"F1 = {custom_f1(best_y_news['y_test'], best_y_news['y_pred'], lbl):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFECETT_VcR7",
        "outputId": "f63f849c-e087-4002-b50f-4d5e9988600c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " News Dataset: Best Accuracy = 0.62, Best k = 1, Split = 60:40\n",
            "Confusion Matrix:\n",
            " [[17  0]\n",
            " [15  8]]\n",
            "Class 0 (politics): Precision = 0.53, Recall = 1.00, F1 = 0.69\n",
            "Class 1 (sports): Precision = 1.00, Recall = 0.35, F1 = 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Iris Comparison\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=best_ratio_iris, random_state=42)\n",
        "sk_model = KNeighborsClassifier(n_neighbors=best_k_iris)\n",
        "sk_model.fit(X_train, y_train)\n",
        "y_pred_sk = sk_model.predict(X_test)\n",
        "print(f\"\\n Iris Sklearn Accuracy: {np.mean(y_test == y_pred_sk):.2f} vs Custom: {best_acc_iris:.2f}\")\n",
        "\n",
        "# News Comparison\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_news, y_news, test_size=best_ratio_news, random_state=42)\n",
        "sk_model = KNeighborsClassifier(n_neighbors=best_k_news)\n",
        "sk_model.fit(X_train, y_train)\n",
        "y_pred_sk = sk_model.predict(X_test)\n",
        "print(f\" News Sklearn Accuracy: {np.mean(y_test == y_pred_sk):.2f} vs Custom: {best_acc_news:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlHjJqVOVvAV",
        "outputId": "44d3e3a5-b9e6-46e3-fa0a-8d93f749240c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Iris Sklearn Accuracy: 1.00 vs Custom: 1.00\n",
            " News Sklearn Accuracy: 0.62 vs Custom: 0.62\n"
          ]
        }
      ]
    }
  ]
}